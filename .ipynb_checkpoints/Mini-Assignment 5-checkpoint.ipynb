{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicing Collocates with Jane Austen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instructions for my mini-assignment 5 are as follows: In Jupyter, using the NLTK Library, complete the following steps to build a concordance for the word “love” from the Jane Austen corpus.\n",
    "\n",
    "1. Import the Jane Austen files.\n",
    "\n",
    "2. Tokenize all of the words.  \n",
    "\n",
    "3. Create a dictionary for word frequencies.\n",
    "\n",
    "            3a. What are the top 10 frequency words (not including stop words)?   \n",
    "\n",
    "            3b. Are the top frequency words the same as in Voyant?\n",
    "\n",
    "3. Create a concordance (10 lines) for the word “love”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import the Jane Austen files and download the NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen/*txt',\n",
       " 'austen/1818 Northanger Abbey.txt',\n",
       " 'austen/1815 Emma.txt',\n",
       " 'austen/1811 Sense and Sensibility.txt',\n",
       " 'austen/1805 Lady Susan.txt',\n",
       " 'austen/1813 Pride and Prejudice.txt',\n",
       " 'austen/1790 Love And Freindship.txt',\n",
       " 'austen/1814 Mansfield Park.txt',\n",
       " 'austen/1818 Persuasion.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "textFiles = glob.glob(\"austen/*txt\")\n",
    "textFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austen/*txt has 0 characters\n",
      "austen/1818 Northanger Abbey.txt has 433410 characters\n",
      "austen/1815 Emma.txt has 883027 characters\n",
      "austen/1811 Sense and Sensibility.txt has 673687 characters\n",
      "austen/1805 Lady Susan.txt has 127290 characters\n",
      "austen/1813 Pride and Prejudice.txt has 684768 characters\n",
      "austen/1790 Love And Freindship.txt has 184984 characters\n",
      "austen/1814 Mansfield Park.txt has 883278 characters\n",
      "austen/1818 Persuasion.txt has 466852 characters\n",
      "total characters:  4337296\n"
     ]
    }
   ],
   "source": [
    "totalCharacters = 0\n",
    "for textFile in textFiles:\n",
    "    f = open(textFile, \"r\", encoding=\"utf-8-sig\")\n",
    "    textString = f.read()\n",
    "    f.close()\n",
    "    chars = len(textString)\n",
    "    print(textFile, \"has\", chars, \"characters\")\n",
    "    totalCharacters += chars\n",
    "print(\"total characters: \", totalCharacters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to tokenize all of the words in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['persuasion',\n",
       " 'by',\n",
       " 'jane',\n",
       " 'austen',\n",
       " '(',\n",
       " '1818',\n",
       " ')',\n",
       " 'chapter',\n",
       " '1',\n",
       " 'sir',\n",
       " 'walter',\n",
       " 'elliot']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austenTokens = nltk.word_tokenize(textString.lower())\n",
    "austenTokens[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've tokenized all the words, we are going to calculate the top ten word frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'persuasion': 1, 'by': 1, 'jane': 1, 'austen': 1, 'chapter': 1, 'sir': 1})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austenRealWordTokensSample = [word for word in austenTokens[:10] if word[0].isalpha()]\n",
    "austenRealWordFrequenciesSample = nltk.FreqDist(austenRealWordTokensSample)\n",
    "austenRealWordFrequenciesSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persuasion         by       jane     austen    chapter        sir \n",
      "         1          1          1          1          1          1 \n"
     ]
    }
   ],
   "source": [
    "austenRealWordFrequenciesSample.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "print(sorted(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample words:  ['persuasion', 'by', 'jane', 'austen', 'chapter', 'sir']\n",
      "sample words not in stopwords list:  ['persuasion', 'jane', 'austen', 'chapter', 'sir']\n"
     ]
    }
   ],
   "source": [
    "print(\"sample words: \", austenRealWordTokensSample)\n",
    "print(\"sample words not in stopwords list: \", [word for word in austenRealWordTokensSample if not word in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anne   could   would captain     mrs  elliot      mr     one    must    lady \n",
      "    494     451     355     303     291     285     256     237     228     215 \n"
     ]
    }
   ],
   "source": [
    "austenRealContentWordTokensLowercase = [word for word in austenTokens \\\n",
    "        if word[0].isalpha() and word not in stopwords]\n",
    "austenRealContentWordFrequencies = nltk.FreqDist(austenRealContentWordTokensLowercase)\n",
    "austenRealContentWordFrequencies.tabulate(10) # show a sample of the top "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 41 matches:\n",
      "uence with elizabeth , and seemed to love her , rather because she would love \n",
      " love her , rather because she would love her , than because elizabeth deserve\n",
      "o do , and she had hardly anybody to love ; but the encounter of such lavish r\n",
      "n acquainted , rapidly and deeply in love . it would be difficult to say which\n",
      " from one who had almost a mother 's love , and mother 's rights , it would be\n",
      "ey ran , quite as full of glee as of love , and apparently more full of captai\n",
      "ht . your sister being with you , my love , i have no scruple at all . you wou\n",
      "lly looking round , ready to fall in love with all the speed which a clear hea\n",
      "y admitted to the honour of being in love with him ; and as for henrietta and \n",
      " , that captain wentworth was not in love with either . they were more in love\n"
     ]
    }
   ],
   "source": [
    "austenText = nltk.Text(austenTokens)\n",
    "austenText.concordance(\"love\", lines=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
