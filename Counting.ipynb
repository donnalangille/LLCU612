{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Assignment 3: Making it Count\n",
    "\n",
    "I will try to reproduce the counting values of specific words in the Jane Austen corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The glob function returns the austen files, located in the local directory. I store them in a variable called textFiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen/1818 Northanger Abbey.txt',\n",
       " 'austen/1815 Emma.txt',\n",
       " 'austen/1811 Sense and Sensibility.txt',\n",
       " 'austen/1805 Lady Susan.txt',\n",
       " 'austen/1813 Pride and Prejudice.txt',\n",
       " 'austen/1790 Love And Freindship.txt',\n",
       " 'austen/1814 Mansfield Park.txt',\n",
       " 'austen/1818 Persuasion.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "textFiles = glob.glob(\"austen/*txt\")\n",
    "textFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can figure out the character counts for each of the novels. First, we declare an empty variable called totalCharacters. Then we create a loop. Everytime we go over a textFile, we use the len function to find the length of each character in a string, and put the value in totalCharacters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austen/1818 Northanger Abbey.txt has 433410 characters\n",
      "austen/1815 Emma.txt has 883027 characters\n",
      "austen/1811 Sense and Sensibility.txt has 673687 characters\n",
      "austen/1805 Lady Susan.txt has 127290 characters\n",
      "austen/1813 Pride and Prejudice.txt has 684768 characters\n",
      "austen/1790 Love And Freindship.txt has 184984 characters\n",
      "austen/1814 Mansfield Park.txt has 883278 characters\n",
      "austen/1818 Persuasion.txt has 466852 characters\n",
      "total characters:  4337296\n"
     ]
    }
   ],
   "source": [
    "totalCharacters = 0\n",
    "for textFile in textFiles:\n",
    "    f = open(textFile, \"r\")\n",
    "    textString = f.read()\n",
    "    f.close()\n",
    "    chars = len(textString)\n",
    "    print(textFile, \"has\", chars, \"characters\")\n",
    "    totalCharacters += chars\n",
    "print(\"total characters: \", totalCharacters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a dictionary so that we can store all the words and their values. The dictionary is called word_count. To create the contents for the dictionary, we make a loop. The first line retrieves the word, then we increase the number of the count by 1 and then it gets stored back in word_count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(textFile).read()\n",
    "words = text.split()\n",
    "word_count = {}\n",
    "for word in words:\n",
    "    count = word_count.get(word, 0)\n",
    "    count += 1\n",
    "    word_count[word] = count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort the dictionary by using the sorted function. We can reverse the ordering so that we get the most used words at the top. For the first 20 key/value pairings in the dictionary, we print the word and the count (number of times it appears in the text). \n",
    "\n",
    "I had help from the following web tutorial: https://www.enigmeta.com/blog/counting-words-with-python-3/\n",
    "\n",
    "However, this doesn't seem to have worked because the numbers are way smaller than the ones in Voyant! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 3111\n",
      "to 2722\n",
      "and 2678\n",
      "of 2521\n",
      "a 1519\n",
      "in 1312\n",
      "was 1270\n",
      "had 1158\n",
      "I 986\n",
      "her 967\n",
      "be 918\n",
      "not 888\n",
      "that 810\n",
      "she 799\n",
      "as 784\n",
      "he 702\n",
      "for 665\n",
      "it 646\n",
      "his 614\n",
      "with 609\n"
     ]
    }
   ],
   "source": [
    "word_count_list = sorted(word_count, key=word_count.get, reverse=True)\n",
    "for word in word_count_list[:20]:\n",
    "    print(word, word_count[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll try and print the occurence of the word \"love\". For some reason it gives me the number 71, which seems very low for a Jane Austen novel, let alone a corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of 'love': 71\n"
     ]
    }
   ],
   "source": [
    "print(\"Occurrences of 'love':\", text.count(\"love\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
